{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz+zeS33pN9hHUenIRus/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gayathri352/data-lake-customer-analytics/blob/main/etl_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Java (required for Spark)\n",
        "!apt-get update -qq\n",
        "!apt-get install -y openjdk-11-jdk-headless\n",
        "\n",
        "# Download and extract Spark 3.4.1 (Stable version)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "!tar -xzf spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Install findspark\n",
        "!pip install -q findspark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtddoG3YaD-f",
        "outputId": "08d1b263-c166-4087-a824-5c052e6ed5bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "openjdk-11-jdk-headless is already the newest version (11.0.26+4-1ubuntu1~22.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 36 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Spark 3.4.1 (works well on Colab)\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Extract it\n",
        "!tar -xzf spark-3.4.1-bin-hadoop3.tgz\n"
      ],
      "metadata": {
        "id": "xPIqEPQKabFd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "# Set environment paths\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "# Initialize findspark\n",
        "findspark.init()\n"
      ],
      "metadata": {
        "id": "xsfewn7eakNm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"PySpark in Colab\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "spark\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Ri5S6PSwa784",
        "outputId": "cb5fd26e-e961-4d2a-d6b2-2bc2bc72c1ee"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fa342e82850>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://29814d3fe6f3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySpark in Colab</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO\n",
        "import pandas as pd\n",
        "\n",
        "# Sample customer transaction data\n",
        "csv_data = \"\"\"CustomerID,TransactionAmount,Timestamp\n",
        "C001,100.5,2023-01-01 10:00:00\n",
        "C002,250.0,2023-01-01 11:00:00\n",
        "C003,320.75,2023-01-01 12:30:00\n",
        "\"\"\"\n",
        "\n",
        "# Save to file\n",
        "df = pd.read_csv(StringIO(csv_data))\n",
        "df.to_csv(\"sample_data.csv\", index=False)\n",
        "\n",
        "# Read into PySpark\n",
        "df_spark = spark.read.csv(\"sample_data.csv\", header=True, inferSchema=True)\n",
        "df_spark.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Phb246cbCgy",
        "outputId": "f0cfebb7-d763-450a-916a-00cf1097d862"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+-------------------+\n",
            "|CustomerID|TransactionAmount|          Timestamp|\n",
            "+----------+-----------------+-------------------+\n",
            "|      C001|            100.5|2023-01-01 10:00:00|\n",
            "|      C002|            250.0|2023-01-01 11:00:00|\n",
            "|      C003|           320.75|2023-01-01 12:30:00|\n",
            "+----------+-----------------+-------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}